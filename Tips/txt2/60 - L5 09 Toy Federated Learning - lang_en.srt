1
00:00:00,000 --> 00:00:04,035
In this lesson, we're going to build what we just learned about in Pi sift

2
00:00:04,035 --> 00:00:08,055
and train our first federated learning model.

3
00:00:08,055 --> 00:00:10,295
Now, that's going to be about as simple as it can get.

4
00:00:10,295 --> 00:00:12,554
What we're going to do is, we're going to just distribute

5
00:00:12,554 --> 00:00:16,125
a tiny toy data set across two different workers,

6
00:00:16,125 --> 00:00:19,545
and then we're going to show and learn how we can

7
00:00:19,545 --> 00:00:23,640
train a model while the data stays on those workers.

8
00:00:23,640 --> 00:00:25,455
First what we want to do is we want to create

9
00:00:25,455 --> 00:00:27,990
a simple model that can learn from some data.

10
00:00:27,990 --> 00:00:30,570
Then we'll look at the processes that we

11
00:00:30,570 --> 00:00:33,180
want to take to be able to train it using federated learning.

12
00:00:33,180 --> 00:00:35,355
So let's start. So we'll create some data.

13
00:00:35,355 --> 00:00:38,585
Say, I've got some data code here.

14
00:00:38,585 --> 00:00:41,135
So this data code is just,

15
00:00:41,135 --> 00:00:43,550
this should look very familiar, we used it above.

16
00:00:43,550 --> 00:00:46,520
It's got two inputs and one output for each example

17
00:00:46,520 --> 00:00:52,580
and we're going to train a simple linear model like we did a few lessons back.

18
00:00:52,580 --> 00:00:58,250
So we need to have in it. So from torch import nn.

19
00:00:58,250 --> 00:00:59,710
I think really the optimizer too.

20
00:00:59,710 --> 00:01:02,035
There we go. So we have a simple linear model.

21
00:01:02,035 --> 00:01:03,840
So what's the first thing we're going to do is?

22
00:01:03,840 --> 00:01:05,280
We want to create our optimizers.

23
00:01:05,280 --> 00:01:09,195
So stochastic gradient ascent.

24
00:01:09,195 --> 00:01:11,295
Params equals model dot.

25
00:01:11,295 --> 00:01:13,425
This is just normal PyTorch code, right?

26
00:01:13,425 --> 00:01:16,560
The first thing that we need to do in our loop is

27
00:01:16,560 --> 00:01:19,880
zero out our gradients. Then, let's make a prediction.

28
00:01:19,880 --> 00:01:23,915
So predict equals model data, beautiful.

29
00:01:23,915 --> 00:01:25,400
We want to calculate the loss function.

30
00:01:25,400 --> 00:01:26,855
So we can do is explicitly.

31
00:01:26,855 --> 00:01:29,000
So we're going to use mean squared error loss here.

32
00:01:29,000 --> 00:01:32,065
I propagate that. Take a step to our optimizer.

33
00:01:32,065 --> 00:01:36,530
Then let's just print the loss. Cool perfect.

34
00:01:36,530 --> 00:01:39,455
All right, so now if we did this multiple times,

35
00:01:39,455 --> 00:01:43,710
we should see this loss go down.

36
00:01:44,900 --> 00:01:48,390
So we'll say, 20 iterations.

37
00:01:48,390 --> 00:01:49,785
Actually that's because of variable,

38
00:01:49,785 --> 00:01:54,240
and we'll have a train method. There we have it.

39
00:01:54,240 --> 00:01:56,735
A simple linear model that can learn on some toy data.

40
00:01:56,735 --> 00:01:59,970
So how do we make this federated?

41
00:01:59,970 --> 00:02:02,700
Well, the first thing we need to do is set up our example.

42
00:02:02,700 --> 00:02:04,610
So right now all of our data is with us.

43
00:02:04,610 --> 00:02:06,470
So you might imagine that our data is in the cloud,

44
00:02:06,470 --> 00:02:08,330
we're on the centralized machine right now.

45
00:02:08,330 --> 00:02:09,800
So when we think about this code,

46
00:02:09,800 --> 00:02:12,465
we think about what we are allowed to access, what we're allowed to use.

47
00:02:12,465 --> 00:02:16,950
Kind of view ourselves internally and our mind as the central server.

48
00:02:16,950 --> 00:02:19,970
What we would like to do is actually move this data off

49
00:02:19,970 --> 00:02:23,555
to individual machines somewhere else that are owned by

50
00:02:23,555 --> 00:02:26,900
other people so that we can then go through the exercise of trying to train

51
00:02:26,900 --> 00:02:30,680
a model that's doing training on those machines.

52
00:02:30,680 --> 00:02:32,690
The first thing to do is split our data into

53
00:02:32,690 --> 00:02:35,330
different pieces and then send it to two different workers.

54
00:02:35,330 --> 00:02:39,880
I believe we still have Bob and Alice from these examples.

55
00:02:39,880 --> 00:02:41,790
Bob and Alice, perfect.

56
00:02:41,790 --> 00:02:45,380
So let's take our data and make data Bob

57
00:02:45,380 --> 00:02:49,115
which is the first two rows, and we'll send it to Bob.

58
00:02:49,115 --> 00:02:54,515
Target Bob will be the first two rows of data again and we'll send it to Bob.

59
00:02:54,515 --> 00:02:56,005
So those are collated with Bob,

60
00:02:56,005 --> 00:02:57,840
co-located with Bob rather.

61
00:02:57,840 --> 00:03:01,160
We'll have data Alice equals data,

62
00:03:01,160 --> 00:03:02,600
we'll send it to Alice.

63
00:03:02,600 --> 00:03:05,645
Realize this should be target, perfect.

64
00:03:05,645 --> 00:03:08,990
All right, now let's take these and put these in a list of tuples.

65
00:03:08,990 --> 00:03:11,910
So we'll say data sets equals,

66
00:03:11,910 --> 00:03:13,320
and then our first one is Bob.

67
00:03:13,320 --> 00:03:16,290
So data, Bob, target Bob.

68
00:03:16,290 --> 00:03:21,725
Then our second one can be data Alice, target Alice.

69
00:03:21,725 --> 00:03:25,660
Now, I want to use the same model and we're going to use the same optimizer.

70
00:03:25,660 --> 00:03:30,710
Perfect. So again, most of this is still very familiar PyTorch code.

71
00:03:30,710 --> 00:03:32,660
The only thing that's different is just the fact that now we

72
00:03:32,660 --> 00:03:35,735
distributed our data set across Bob and Alice's machines.

73
00:03:35,735 --> 00:03:38,510
So the first half of our data set is on Bob's machine and

74
00:03:38,510 --> 00:03:41,870
the second half of our data set is on Alice's machine.

75
00:03:41,870 --> 00:03:44,185
So in our for loop, previously,

76
00:03:44,185 --> 00:03:47,825
we iterated over every example and we basically trained on the whole data set.

77
00:03:47,825 --> 00:03:49,265
This one batch.

78
00:03:49,265 --> 00:03:51,290
We trained in the whole thing, every time step.

79
00:03:51,290 --> 00:03:54,050
But now, we have an extra for loop where we iterate over

80
00:03:54,050 --> 00:03:57,065
each individual person in our example.

81
00:03:57,065 --> 00:03:58,355
So let's see here.

82
00:03:58,355 --> 00:04:00,605
So let's just say that we have one example.

83
00:04:00,605 --> 00:04:02,870
So we'll say, target data.

84
00:04:02,870 --> 00:04:05,090
Target equals data sets zeros.

85
00:04:05,090 --> 00:04:06,260
This is the first data set.

86
00:04:06,260 --> 00:04:08,510
If we look at data, it is a pointer.

87
00:04:08,510 --> 00:04:12,995
So that's appointed tensor and the ID of the pointer is this number,

88
00:04:12,995 --> 00:04:15,080
the idea to pointer on Bob's machine.

89
00:04:15,080 --> 00:04:19,385
So this is a pointer to this tensor that's located on Bob's machine.

90
00:04:19,385 --> 00:04:23,660
So before we really get started here, we have an issue.

91
00:04:23,660 --> 00:04:28,625
So our model is located here or as our data is located on Bob's machine.

92
00:04:28,625 --> 00:04:35,250
So the first thing we need to do is say, model equals models.senddata.location.

93
00:04:35,250 --> 00:04:37,115
So if you remember,

94
00:04:37,115 --> 00:04:38,725
when we talked about pointers,

95
00:04:38,725 --> 00:04:42,960
each pointer has a reference to the worker,

96
00:04:42,960 --> 00:04:45,680
the virtual worker that exists on the other machine.

97
00:04:45,680 --> 00:04:48,170
In this case, we're dealing with virtual workers.

98
00:04:48,170 --> 00:04:49,610
This actually is the workers,

99
00:04:49,610 --> 00:04:51,980
this is the Python object that we interact with.

100
00:04:51,980 --> 00:04:54,470
In the case of this being a pointer to another machine,

101
00:04:54,470 --> 00:04:58,550
this is a client that basically knows how to send messages to the other worker.

102
00:04:58,550 --> 00:05:00,230
But for all intents and purposes,

103
00:05:00,230 --> 00:05:03,500
we can just treat this as the worker. So what does this line do?

104
00:05:03,500 --> 00:05:09,095
This line iterates through every tensor inside this model.

105
00:05:09,095 --> 00:05:11,765
So in this case, it's a weights tensor in a bias tensor,

106
00:05:11,765 --> 00:05:13,355
because linear model has two tensors.

107
00:05:13,355 --> 00:05:16,630
So in basically, every tensor in model.parameter.

108
00:05:16,630 --> 00:05:18,780
So both of these tensors.

109
00:05:18,780 --> 00:05:24,140
It's going to call dot send in place on all those tensors.

110
00:05:24,140 --> 00:05:26,880
So if I run this and then look at the parameters again,

111
00:05:26,880 --> 00:05:31,975
as you can see now, they're all pointers to data that is elsewhere.

112
00:05:31,975 --> 00:05:36,170
So the nice thing here is that this convenience function that allows us to say,

113
00:05:36,170 --> 00:05:42,485
hey take this model and send it to wherever the data happens to be located.

114
00:05:42,485 --> 00:05:45,640
So that's going to be our second step.

115
00:05:45,640 --> 00:05:52,175
Now the next thing that we can do is same steps that we did before.

116
00:05:52,175 --> 00:05:54,995
So we'll call zero grad and optimizer,

117
00:05:54,995 --> 00:05:56,660
which was zero at the gradients.

118
00:05:56,660 --> 00:05:58,700
Pred equals model data.

119
00:05:58,700 --> 00:06:00,790
So this makes it prediction.

120
00:06:00,790 --> 00:06:04,335
Use the wrong handle there. There we go.

121
00:06:04,335 --> 00:06:07,110
Again, actually, this was a useful error.

122
00:06:07,110 --> 00:06:08,760
So this was the error.

123
00:06:08,760 --> 00:06:11,585
This is the wrong image now because I passed in the wrong tensor.

124
00:06:11,585 --> 00:06:16,040
So underscore data, which is from right here and then we're going to say

125
00:06:16,040 --> 00:06:21,485
loss equals pred minus target squared and take the sum.

126
00:06:21,485 --> 00:06:24,260
I did it again. Silly me.

127
00:06:24,260 --> 00:06:30,995
Lost.backward. Again, all this is being executed on the remote machine and then opt.step.

128
00:06:30,995 --> 00:06:34,225
One last thing which brings the model back to us.

129
00:06:34,225 --> 00:06:37,610
So now, the first thing that we do.

130
00:06:37,610 --> 00:06:39,440
Send the model to the remote worker,

131
00:06:39,440 --> 00:06:40,805
send the model to the data.

132
00:06:40,805 --> 00:06:43,510
This is the federated part.

133
00:06:43,510 --> 00:06:48,750
Do normal training. Get smarter model back.

134
00:06:48,750 --> 00:06:51,780
As you can see, we can train in this way.

135
00:06:51,780 --> 00:06:55,970
However, the even nicer thing is that now we can iterate through this data sets

136
00:06:55,970 --> 00:07:02,090
object and our model will send in train at all the locations that the data is located in.

137
00:07:02,090 --> 00:07:10,855
Pretty cool, huh? So now, we wrap this into an outer iterator. There we go.

138
00:07:10,855 --> 00:07:14,215
Now, our model trains across a distributed data set.

139
00:07:14,215 --> 00:07:18,025
Now this is a very small change.

140
00:07:18,025 --> 00:07:21,160
Thanks to the convenience of the PySyft library

141
00:07:21,160 --> 00:07:24,940
most of our code still looks like normal PyTorch code,

142
00:07:24,940 --> 00:07:28,795
and we have a full flexibility of the PyTorch API at our disposal.

143
00:07:28,795 --> 00:07:32,170
The only thing that we really needed to change was where

144
00:07:32,170 --> 00:07:36,415
the model was located when we were performing federated learning.

145
00:07:36,415 --> 00:07:42,700
Now, this takes an important step towards preserving the privacy of our users.

146
00:07:42,700 --> 00:07:47,895
However, there are still a couple of issues with this particular example.

147
00:07:47,895 --> 00:07:51,220
When we go into the next examples in the next lessons,

148
00:07:51,220 --> 00:07:54,080
they're really going to be focusing on how we can further alleviate

149
00:07:54,080 --> 00:07:57,215
and further preserve the privacy of the individuals who are involved.

150
00:07:57,215 --> 00:07:59,465
So the first one is this.

151
00:07:59,465 --> 00:08:03,110
So if you think about this model being sent,

152
00:08:03,110 --> 00:08:06,215
trained on one example and then we're getting it back,

153
00:08:06,215 --> 00:08:09,920
if I look at the diff between these two models,

154
00:08:09,920 --> 00:08:14,540
it's quite possible that I could really reverse engineer quite a bit of information about

155
00:08:14,540 --> 00:08:20,540
what this data actually does or what the data actually is on the other machine.

156
00:08:20,540 --> 00:08:23,890
So for example, if you're familiar with word embeddings.

157
00:08:23,890 --> 00:08:26,150
So often a neural net will have word embeddings.

158
00:08:26,150 --> 00:08:28,090
Maybe it's a sentiment classifier or

159
00:08:28,090 --> 00:08:30,845
you're training a word to vec model or something like this.

160
00:08:30,845 --> 00:08:34,640
If say I send the model to Bob,

161
00:08:34,640 --> 00:08:38,450
Bob performed one batch of training on a tweet.

162
00:08:38,450 --> 00:08:40,215
For example, maybe the tweet said,

163
00:08:40,215 --> 00:08:42,780
"I like purple peanuts."

164
00:08:42,780 --> 00:08:48,110
Then, Bob sent them all back to me after having only trained on that one tweet.

165
00:08:48,110 --> 00:08:50,510
Well, I could look inside my word embeddings and I can say,

166
00:08:50,510 --> 00:08:53,070
"Hey, which embeddings actually changed?

167
00:08:53,070 --> 00:08:55,870
Which embeddings did Bob modify?"

168
00:08:55,870 --> 00:08:58,220
What that would end up telling me is that

169
00:08:58,220 --> 00:09:00,890
the only embeddings that Bob actually modified were,

170
00:09:00,890 --> 00:09:03,060
"I like purple and peanuts."

171
00:09:03,060 --> 00:09:06,290
This would allow me to basically reverse engineer Bob's data by just

172
00:09:06,290 --> 00:09:10,210
looking at the difference between the model that I send and the model that I got back.

173
00:09:10,210 --> 00:09:15,215
Now, there are two main ways that we mitigate this.

174
00:09:15,215 --> 00:09:20,475
The first one is that we just train more than one iteration.

175
00:09:20,475 --> 00:09:23,060
So when we train over and over and over again,

176
00:09:23,060 --> 00:09:28,790
we train with a large amount of data on Bob's machine like this

177
00:09:28,790 --> 00:09:32,000
further gives Bob a certain degree of privacy because it becomes

178
00:09:32,000 --> 00:09:35,240
more difficult to reverse engineer what the gradients,

179
00:09:35,240 --> 00:09:37,070
where as Bob works with more data.

180
00:09:37,070 --> 00:09:39,079
So in the case of the word embeddings example,

181
00:09:39,079 --> 00:09:42,110
if Bob actually modifies every word embedding because he trains

182
00:09:42,110 --> 00:09:45,160
on all of the English Wikipedia when I sent the model to him,

183
00:09:45,160 --> 00:09:48,305
then it would be much more difficult to know exactly what it said.

184
00:09:48,305 --> 00:09:51,350
But this is again still a bit of a hand-wave issue.

185
00:09:51,350 --> 00:09:54,260
It's not really solving the problem of

186
00:09:54,260 --> 00:09:59,555
guaranteeing that we can't reverse engineer something from from Bob's data.

187
00:09:59,555 --> 00:10:03,635
So the next strategy that we employ is that instead

188
00:10:03,635 --> 00:10:08,510
of bringing the model directly back to us and then sending it to Alice,

189
00:10:08,510 --> 00:10:14,630
we instead train multiple different models in parallel on different workers,

190
00:10:14,630 --> 00:10:17,015
on different people's data sets.

191
00:10:17,015 --> 00:10:22,730
So that then we can average those models together and the only model that we see,

192
00:10:22,730 --> 00:10:28,250
the only model that we get back to us is an average of multiple people's models.

193
00:10:28,250 --> 00:10:33,090
If you've already taken the differential privacy section of this course,

194
00:10:33,090 --> 00:10:36,800
then you'll be familiar with the concept that when we average information,

195
00:10:36,800 --> 00:10:40,400
when we take sums of information across multiple different people,

196
00:10:40,400 --> 00:10:42,605
then we begin to be able to create

197
00:10:42,605 --> 00:10:46,960
plausible deniability as to who actually modified each weight.

198
00:10:46,960 --> 00:10:48,650
This matters here.

199
00:10:48,650 --> 00:10:51,050
So for example to go back to the word embedding example,

200
00:10:51,050 --> 00:10:54,760
let's say that I was training on a Twitter corpus across a 100 different people.

201
00:10:54,760 --> 00:10:56,690
So I sent a copy of the model to

202
00:10:56,690 --> 00:11:01,855
a 100 different people and each of them trained a few 1,000 tweets on the local machine.

203
00:11:01,855 --> 00:11:05,645
Then I get back a model and I can see all the different word embeddings that are

204
00:11:05,645 --> 00:11:10,590
modified and someone modified the word password.

205
00:11:11,920 --> 00:11:15,950
The trouble is that because the model has already been averaged,

206
00:11:15,950 --> 00:11:18,140
I don't know which person

207
00:11:18,140 --> 00:11:22,145
actually touched the word embedding password. Could have been multiple people.

208
00:11:22,145 --> 00:11:24,080
Could have been just one person.

209
00:11:24,080 --> 00:11:25,490
It's tough for me to know.

210
00:11:25,490 --> 00:11:29,795
If you remember the definitions that we have previously about epsilon and delta,

211
00:11:29,795 --> 00:11:33,230
then if we add a little bit of noise after the aggregation,

212
00:11:33,230 --> 00:11:35,270
then we can further protect the privacy of

213
00:11:35,270 --> 00:11:37,850
individuals such that maybe no one touched the password,

214
00:11:37,850 --> 00:11:40,160
and this is actually just a little bit of the noise that was

215
00:11:40,160 --> 00:11:43,085
added to the model during the aggregation process.

216
00:11:43,085 --> 00:11:44,150
So as you can see,

217
00:11:44,150 --> 00:11:46,760
this is really where we start to cross over from

218
00:11:46,760 --> 00:11:51,395
just pure remote execution back into

219
00:11:51,395 --> 00:11:53,810
some of the concepts and the core concepts around privacy

220
00:11:53,810 --> 00:11:56,465
that we learned about in the differential privacy section.

221
00:11:56,465 --> 00:11:58,775
But first, before we get to all this,

222
00:11:58,775 --> 00:12:01,010
we're going to figure out how we can train

223
00:12:01,010 --> 00:12:03,710
a model on multiple different workers at the same time

224
00:12:03,710 --> 00:12:09,440
and secondly how can we properly perform the great aggregations,

225
00:12:09,440 --> 00:12:12,290
and then really building out the tools that we're going to need for this and

226
00:12:12,290 --> 00:12:16,175
the extensions of PySyft that we're going to need to know about to use this.

227
00:12:16,175 --> 00:12:19,350
So we're going to unpack in the next section. See you there.

