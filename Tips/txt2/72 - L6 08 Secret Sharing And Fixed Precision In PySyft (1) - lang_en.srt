1
00:00:00,000 --> 00:00:01,650
So in this video, we're going to take some of

2
00:00:01,650 --> 00:00:04,470
the theoretical concepts we've been learning about in the last few sections,

3
00:00:04,470 --> 00:00:07,140
specifically additive secret sharing and fixed precision

4
00:00:07,140 --> 00:00:10,230
representation and show how you can leverage PySyft to do

5
00:00:10,230 --> 00:00:13,260
this in sort of an easy and intuitive way where it just feels like you're

6
00:00:13,260 --> 00:00:15,300
using normal PyTorch tensors

7
00:00:15,300 --> 00:00:18,000
even though they're being encoded in this way under the hood.

8
00:00:18,000 --> 00:00:19,980
But the first thing I'd like for us to do is clear out

9
00:00:19,980 --> 00:00:21,720
the objects that are inside of Bob,

10
00:00:21,720 --> 00:00:22,770
Alice, and secure worker,

11
00:00:22,770 --> 00:00:26,790
we're going to use these as our example workers to share things on,

12
00:00:26,790 --> 00:00:28,110
and then we want to create a little bit of data.

13
00:00:28,110 --> 00:00:32,100
So do our standard 1, 2, 3, 4,

14
00:00:32,100 --> 00:00:35,535
5 tensor. Looks good,

15
00:00:35,535 --> 00:00:40,570
and now let's show you this next method called share.

16
00:00:41,570 --> 00:00:44,770
Now, we can pass in a series of workers here,

17
00:00:44,770 --> 00:00:47,860
arbitrary number, either 2 or 3 or 20,

18
00:00:47,860 --> 00:00:53,140
and what this will do is actually split this x value into

19
00:00:53,140 --> 00:00:58,020
multiple different additive secret shares and then send those shares to Bob,

20
00:00:58,020 --> 00:01:04,630
Alice, and secure worker such that we will have pointers to that data.

21
00:01:04,630 --> 00:01:06,950
So let me show you what I mean.

22
00:01:07,280 --> 00:01:09,750
So when we call.share,

23
00:01:09,750 --> 00:01:11,695
what it did on the hood has generated

24
00:01:11,695 --> 00:01:17,800
three different pointers to the three different shares that we had sent to Bob,

25
00:01:17,800 --> 00:01:18,820
Alice, and secure worker.

26
00:01:18,820 --> 00:01:22,360
So now, if we actually take a look at say one of these shares,

27
00:01:24,560 --> 00:01:29,700
we can see is a bunch of large random numbers.

28
00:01:29,700 --> 00:01:33,115
However, the nice thing about this is that we can actually,

29
00:01:33,115 --> 00:01:36,485
again just like we did with regular pointer tensors,

30
00:01:36,485 --> 00:01:40,930
just pretend that there's another tensor.

31
00:01:42,410 --> 00:01:45,465
As you can see, it's created another share on Bob's machine,

32
00:01:45,465 --> 00:01:47,680
created another share on all three of these guys, so Bob,

33
00:01:47,680 --> 00:01:49,390
Alice, and secure worker,

34
00:01:49,390 --> 00:01:52,720
and y is another additively shared tensor.

35
00:01:52,720 --> 00:01:55,390
If we call y.get,

36
00:01:55,390 --> 00:02:03,910
it will decrypt this encrypted tensor and gives us back the result of our computation,

37
00:02:03,910 --> 00:02:05,260
the result of our addition 2,

38
00:02:05,260 --> 00:02:07,615
4, 6, 8, 10.

39
00:02:07,615 --> 00:02:11,940
Now, however, we did mention before that these are integers,

40
00:02:11,940 --> 00:02:13,590
so we're doing integer computation here.

41
00:02:13,590 --> 00:02:16,000
Whereas in the context of federate learning,

42
00:02:16,000 --> 00:02:18,590
we want to be able to do this on decimal valued numbers.

43
00:02:18,590 --> 00:02:22,100
So this is where a PySyft also adds in a bit of extra functionality.

44
00:02:22,100 --> 00:02:26,880
So let's say we have our canonical tensor again,

45
00:02:27,970 --> 00:02:32,090
but this time we're going to say actually now we'll suit decimal values.

46
00:02:32,090 --> 00:02:41,385
So 0.1, 0.2, 0.3, 0.4, 0.5.

47
00:02:41,385 --> 00:02:45,170
Cool. Now, we're going to encode

48
00:02:45,170 --> 00:02:55,560
this using fixed precision and x is now our fixed precision number.

49
00:02:55,560 --> 00:03:00,180
Under the hood inside of x are the values 100,

50
00:03:00,180 --> 00:03:02,580
200, 300, 400, and 500.

51
00:03:02,580 --> 00:03:05,540
However, this is still getting interpreted in

52
00:03:05,540 --> 00:03:08,390
all the mathematical operations are such that if

53
00:03:08,390 --> 00:03:11,570
we were to go back to a regular encoding,

54
00:03:11,570 --> 00:03:15,770
it would still look like this 0.1, 0.2, 0.3, 0.4.

55
00:03:15,770 --> 00:03:20,670
So if I go to x.float_precision,

56
00:03:22,030 --> 00:03:29,765
excuse me, so you can see it restores the original values.

57
00:03:29,765 --> 00:03:33,540
Now, you might find this to be an interesting representation.

58
00:03:33,540 --> 00:03:36,725
This actually alludes to a little bit of how PySyft works under the hood.

59
00:03:36,725 --> 00:03:39,320
So this is actually a tensor chain.

60
00:03:39,320 --> 00:03:43,195
At the top, we have sort of a dummy PyTorch wrapper.

61
00:03:43,195 --> 00:03:45,350
There are reasons why we have to do this to make it

62
00:03:45,350 --> 00:03:47,360
compatible with rest of the PyTorch ecosystem.

63
00:03:47,360 --> 00:03:53,240
This forwards all commands to it's child, so basically x.child.

64
00:03:53,240 --> 00:03:54,860
So let me just show you this.

65
00:03:54,860 --> 00:03:58,110
I'll create another fixed precision tensor.

66
00:04:03,140 --> 00:04:07,295
So the type of x is a Torch tensor.

67
00:04:07,295 --> 00:04:10,890
The type of x.child is a fixed precision tensor.

68
00:04:10,890 --> 00:04:14,365
The type of x.child.child, which you can see where this is going,

69
00:04:14,365 --> 00:04:15,750
is another native tensor.

70
00:04:15,750 --> 00:04:18,900
So this native tensor is actually the raw data.

71
00:04:18,900 --> 00:04:21,230
This is the actual encoding of this 100,

72
00:04:21,230 --> 00:04:23,410
200, 300, 400, and 500.

73
00:04:23,410 --> 00:04:27,180
This is what we call an interpreter.

74
00:04:27,180 --> 00:04:29,800
So whenever you execute a command,

75
00:04:29,800 --> 00:04:32,450
it gets called on this wrapper on the top which

76
00:04:32,450 --> 00:04:34,990
then passes it off to.child automatically.

77
00:04:34,990 --> 00:04:38,430
It will always pass it off to.child..child says, "Okay.

78
00:04:38,430 --> 00:04:41,210
You're trying to say add two tensors together."

79
00:04:41,210 --> 00:04:45,440
Well, since I am a fixed precision interpreter,

80
00:04:45,440 --> 00:04:48,350
I know how to add this appropriately given

81
00:04:48,350 --> 00:04:51,580
the fact that the underlying data is encoded in a particular way.

82
00:04:51,580 --> 00:04:53,420
This is how it knows how to do

83
00:04:53,420 --> 00:04:58,325
the appropriate operations because on this sort of specially encoded data,

84
00:04:58,325 --> 00:05:02,165
which it then calls on.child which actually manipulates the data.

85
00:05:02,165 --> 00:05:04,640
So as it turns out, pointers actually work this way too. All right.

86
00:05:04,640 --> 00:05:07,760
So pointer is a special type that when the wrapper calls the pointer,

87
00:05:07,760 --> 00:05:12,470
the pointer knows how to handle the remote encoding of this particular data.

88
00:05:12,470 --> 00:05:14,960
So it's just a little bit on how PySyft tensors work in

89
00:05:14,960 --> 00:05:18,440
a bit more advanced way and what this print statement is really saying.

90
00:05:18,440 --> 00:05:20,510
It's sort of saying we have wrapper and this little

91
00:05:20,510 --> 00:05:22,595
caret says it's sort of a.child signal.

92
00:05:22,595 --> 00:05:24,620
So this is the child of the wrapper and in

93
00:05:24,620 --> 00:05:27,995
this actual data is a child of the fixed precision tensor.

94
00:05:27,995 --> 00:05:30,230
So there you go. Of course,

95
00:05:30,230 --> 00:05:32,120
we can go y equals x plus x,

96
00:05:32,120 --> 00:05:38,820
y is still a fixed precision tensor, y equals y.float_precision.

97
00:05:38,840 --> 00:05:42,245
There you go, we have the result of our computation.

98
00:05:42,245 --> 00:05:43,925
As you might expect,

99
00:05:43,925 --> 00:05:45,620
we can actually use these together.

100
00:05:45,620 --> 00:05:51,450
So if I said x equals th.tensor([0.1, 0.2,

101
00:05:51,450 --> 00:05:56,820
0.3]) and I said fixed precision and share with Bob, Alice,

102
00:05:56,820 --> 00:06:01,260
and secure worker, y equals x,

103
00:06:01,260 --> 00:06:03,765
so as you can see, this is the nesting.

104
00:06:03,765 --> 00:06:06,045
So at the top we have the wrapper.

105
00:06:06,045 --> 00:06:08,780
This goes to a fixed precision tensor which says, "Okay.

106
00:06:08,780 --> 00:06:13,640
Interpret everything beneath me as if it's actually a decimal,

107
00:06:13,640 --> 00:06:16,010
but I know that it's going to be encoded as an integer."

108
00:06:16,010 --> 00:06:20,285
It's child is an additive sharing tensor which knows how to encode integers.

109
00:06:20,285 --> 00:06:22,310
So as you remember here,

110
00:06:22,310 --> 00:06:24,260
the child of a fixed precision tensor

111
00:06:24,260 --> 00:06:26,510
always has to be an integer tensor because the whole point is to be able to

112
00:06:26,510 --> 00:06:31,120
store a theoretically decimal value number as an integer under the hood.

113
00:06:31,120 --> 00:06:33,650
Since additive secret sharing knows how to deal with integers,

114
00:06:33,650 --> 00:06:35,540
it then has these pointers to Bob,

115
00:06:35,540 --> 00:06:37,295
Alice, and secure worker.

116
00:06:37,295 --> 00:06:42,080
So I can go y equals x plus x. Y also ends up being

117
00:06:42,080 --> 00:06:46,130
a fixed precision tensor wrapping and additive sharing tensor and I can

118
00:06:46,130 --> 00:06:51,570
call y equals y.get.float_precision,

119
00:06:52,540 --> 00:06:55,880
and now we have the result of our computation.

120
00:06:55,880 --> 00:06:59,090
So I hope you really see the power that the PySyft is able to give you,

121
00:06:59,090 --> 00:07:01,580
these multiple layers of interpretation,

122
00:07:01,580 --> 00:07:05,545
of abstraction, and of message forwarding to remote machines.

123
00:07:05,545 --> 00:07:06,900
In the next section,

124
00:07:06,900 --> 00:07:09,560
we're going to talk about the next project that you want to be able to

125
00:07:09,560 --> 00:07:13,410
use these kinds of tools for. So I'll see you then.

